## Calendario 2020 (preliminar)

### Semana 1

* Cátedra: Introducción, IA vs ML vs DL, ¿Por qué DL ahora? ([video](https://www.youtube.com/watch?v=BASByOlqqkc&list=PLBjZ-ginWc1e0_Dp4heHglsjJmacV_F20&index=1))
* Cátedra: Perceptrón, funciones de activación, y representación matricial ([video](https://www.youtube.com/watch?v=mDCxK2Pu0mA&list=PLBjZ-ginWc1e0_Dp4heHglsjJmacV_F20&index=2))

### Semana 2

* Cátedra: UAT, Redes Feed-Forward, y función de salida (softmax) ([video](https://www.youtube.com/watch?v=eV-N1ozcZrk&list=PLBjZ-ginWc1e0_Dp4heHglsjJmacV_F20&index=3))
* Auxiliar: Colab, Pytorch y Tensores, una introducción práctica ([video](https://www.youtube.com/watch?v=gjTV_7X2O9Y&feature=youtu.be))

### Semana 3

* Cátedra: Descenso de Gradiente para encontrar los parámetros de una red ([video](https://www.youtube.com/watch?v=G4dnRSSC6Kw))
* Auxiliar: Aclaración de dudas sobre la Tarea 1

### Semana 4

* Cátedra: Introducción a Backpropagation ([video](https://www.youtube.com/watch?v=1EUAoM1EhM0))
* Cátedra: Continuación Backpropagation ([video](https://www.youtube.com/watch?v=Gp2rY7LvTyQ))

### Semana 5

* Cátedra: Tensores, Notación de Einstein, y Regla de la Cadena Tensorial ([video](https://www.youtube.com/watch?v=pLUNS_tK-K8))
* Cátedra: Entropía Cruzada y Backpropagation a mano con Tensores ([video](https://www.youtube.com/watch?v=e_1lis8ByyI))

### Semana 6

* Cátedra: Red FF a mano en pytorch (y la versión estilo pytorch) ([video](https://www.youtube.com/watch?v=y6aD4WG-rOw))
* Cátedra: Generalización, Test-Dev-Train set, e Intro. a Regularización ([video](https://www.youtube.com/watch?v=5gAJeY-HHtg))

### Semana 7

* Cátedra: Ensemble, Dropout, y Desvanecimiento de Gradiente ([video](https://www.youtube.com/watch?v=4cJlTns7noE))
* Cátedra: Inicialización, Normalización y Batch Normalization ([video](https://www.youtube.com/watch?v=izOwC2my1Kw))

### Semana 8

* Cátedra: Algoritmos de Optimización, SGD con Momentum, RMSProp, Adam ([video](https://www.youtube.com/watch?v=FBsiDndtdVg))
* Cátedra: Aclaración de dudas

### Semana 9

* Cátedra: Introducción a Redes Convolucionales ([video](https://www.youtube.com/watch?v=vSHSmiKiiDw))
* Cátedra: Redes Convolucionales: Pooling, AlexNet, VGG ([video](https://www.youtube.com/watch?v=ju7nKaFaFvc))

### Semana 10

* Cátedra: Redes Convolucionales: InceptionNet (GoogleNet) ([video](https://www.youtube.com/watch?v=AxWG1aLWODE))
* Cátedra: Redes Convolucionales: ResNet, DenseNet ([video](https://www.youtube.com/watch?v=C7S7wBsg2KE))

### Semana 11

* Cátedra: Introducción a Redes Recurrentes ([video](https://www.youtube.com/watch?v=yHzflmQ9EoY))
* Cátedra: Arquitectura de Redes Recurrentes ([video](https://www.youtube.com/watch?v=Bcy_no-u_BM))

### Semana 12

* Cátedra: Auto-regresión, Language Modelling, y Arquitecturas Seq-to-Seq ([video](https://www.youtube.com/watch?v=bsKwb7wjYYc))

### Semana 13

* Cátedra: RNNs con Compuertas y Celdas de Memoria: GRU y LSTM ([video](https://www.youtube.com/watch?v=cDT9oYyXgjo))
* Cátedra: Atención Neuronal ([video](https://www.youtube.com/watch?v=B9hMAvoWE7w))

### Semana 14

* Cátedra: Transformers ([video](https://www.youtube.com/watch?v=QTX6VgOWwE4))
* Cátedra: Graph Neural Networks

### Semana 15

* Cátedra: Generative Adversarial Networks
* Cátedra: Avanzado
